{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkSs-e1STKJo"
   },
   "source": [
    "# Train Test Transformer based log outlier detection framework\n",
    "\n",
    "\n",
    "*   Only suitable for log data that have logical relationship between neighbor logs\n",
    "    - suitable for : HDFS; Hadoop; Openstack\n",
    "    - not suitable for: BGL; Thunderbird (no obvious relationship)  \n",
    "\n",
    "\n",
    "*   Same network architecture, but different embedding size for different log system. Different network objects are separately trained for different log system\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7ZgMtn2Uago"
   },
   "source": [
    "# Preparing\n",
    "\n",
    "\n",
    "*   fix bug of pytorch transformer framework\n",
    "*   Connect to Gdrive\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TBVxjbb30IMF"
   },
   "outputs": [],
   "source": [
    "# from torch.nn import Transformer\n",
    "# float 16\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import LightningDataModule\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from typing import Optional\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import sklearn\n",
    "\n",
    "class LogOutlier(LightningModule):\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.2, padding_value = 512, target_value = 0,lr = 1e-3):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.ninp = ninp\n",
    "        self.padding_value = padding_value\n",
    "        self.target_value = target_value\n",
    "        # token embedding\n",
    "        self.encoder = Embeddings(ninp, ntoken)\n",
    "        # positional encoding\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "\n",
    "        # transformer encoder\n",
    "        encoder_layers = TransformerEncoderLayerAttention(ninp, nhead, nhid, dropout)  # encoder_layer\n",
    "        self.transformer_encoder = TransformerEncoderAttention(encoder_layers, nlayers)\n",
    "\n",
    "\n",
    "\n",
    "        self.decoder = nn.Linear(ninp, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1  # original 0.1\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, key_padding_mask, att_mask=None, require_attention=False, result_mask=None):\n",
    "        # att_mask : for every sequence in batch is the same\n",
    "        src = src.t()\n",
    "        # pos encoder suppose input begin with sequence length\n",
    "        src = self.encoder(src)\n",
    "\n",
    "        src = self.pos_encoder(src)\n",
    "        # attention! transformer need different input structure, first place is not batch size\n",
    "\n",
    "        output, attention_list = self.transformer_encoder(src, src_key_padding_mask=key_padding_mask, mask=att_mask)\n",
    "\n",
    "        src = None\n",
    "\n",
    "        # change back to normal shape\n",
    "        # att_mask  size(batch_size, sequence length mask)\n",
    "        output = output.permute(1, 0, 2)[result_mask]\n",
    "\n",
    "        output = self.decoder(output)\n",
    "\n",
    "        if require_attention:\n",
    "            return output, attention_list\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        src_key_padding_mask = (x == self.padding_value)\n",
    "        # mask still on same device as x\n",
    "        output_mask = (x == self.target_value)\n",
    "        logits = self(x, key_padding_mask = src_key_padding_mask, result_mask =output_mask )\n",
    "        loss_function = nn.CrossEntropyLoss()\n",
    "        loss = loss_function(logits, y)\n",
    "        self.log('my_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=self.lr)\n",
    "        scheduler = StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}\n",
    "\n",
    "\n",
    "#######################################################\n",
    "#######################################################\n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        # d_model = 0.25*vocab\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.lut.weight.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    # input must be seq length\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=3000):\n",
    "        # max_len does't affect positional encoding, z.B. for sequence with length 30 ,the positional encoding of 3000 and 30 is exactly same  \n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "class TransformerEncoderLayerAttention(TransformerEncoderLayer):\n",
    "    def forward(self, src: Tensor, src_mask: Optional[Tensor] = None, src_key_padding_mask: Optional[Tensor] = None) :\n",
    "            r\"\"\"Pass the input through the encoder layer.\n",
    "\n",
    "            Args:\n",
    "                src: the sequence to the encoder layer (required).\n",
    "                src_mask: the mask for the src sequence (optional).\n",
    "                src_key_padding_mask: the mask for the src keys per batch (optional).\n",
    "\n",
    "            Shape:\n",
    "                see the docs in Transformer class.\n",
    "            \"\"\"\n",
    "            src2,attention_weight = self.self_attn(src, src, src, attn_mask=src_mask,\n",
    "                                key_padding_mask=src_key_padding_mask)\n",
    "            src = src + self.dropout1(src2)\n",
    "            src = self.norm1(src)\n",
    "            src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "            src = src + self.dropout2(src2)\n",
    "            src = self.norm2(src)\n",
    "            return src, attention_weight\n",
    "\n",
    "class TransformerEncoderAttention(TransformerEncoder):\n",
    "    def forward(self, src: Tensor, mask: Optional[Tensor] = None, src_key_padding_mask: Optional[Tensor] = None):\n",
    "            r\"\"\"Pass the input through the encoder layers in turn.\n",
    "\n",
    "            Args:\n",
    "                src: the sequence to the encoder (required).\n",
    "                mask: the mask for the src sequence (optional).\n",
    "                src_key_padding_mask: the mask for the src keys per batch (optional).\n",
    "\n",
    "            Shape:\n",
    "                see the docs in Transformer class.\n",
    "            \"\"\"\n",
    "            output = src\n",
    "            attention_list = []\n",
    "\n",
    "            for mod in self.layers:\n",
    "                output,attention = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask)\n",
    "                attention_list.append(attention.to(torch.device('cpu')))\n",
    "                attention = None\n",
    "            if self.norm is not None:\n",
    "                output = self.norm(output)\n",
    "\n",
    "            return output,attention_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJHLtgQlUllY"
   },
   "source": [
    "# Define Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U56d2CYOUoJ3"
   },
   "source": [
    "# Define Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31zDAQApmWEm"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class sequence_generator(Dataset):\n",
    "    def __init__(self,target_mask = 0, padding_number = 100, device = torch.device('cpu'), start_token = 62, end_token = 63, need_start_end = False, horizon = False):\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device('cuda')\n",
    "        self.tokens = set()\n",
    "        self.sequence = {}\n",
    "        self.max_length = 0# key: instance_id value: template id sequences\n",
    "        self.target_mask = target_mask\n",
    "        self.padding_number = padding_number\n",
    "        \n",
    "        self.seq_data = []\n",
    "        self.device = device\n",
    "\n",
    "        self.start_token = start_token\n",
    "        self.end_token = end_token\n",
    "        self.need_start_end = need_start_end\n",
    "\n",
    "        self.horizon = horizon\n",
    "    \n",
    "    def single_add(self,instance_id,template_id):\n",
    "        self.tokens.update([template_id])\n",
    "        if instance_id not in self.sequence.keys():\n",
    "            self.sequence[instance_id] = []\n",
    "        self.sequence[instance_id].append(template_id)\n",
    "        #update max_length\n",
    "        self.max_length = max(self.max_length,len(self.sequence[instance_id]))\n",
    "    \n",
    "    def list_add(self,instance_id,template_id):\n",
    "        self.tokens.update(template_id)\n",
    "        for i in range(len(instance_id)):\n",
    "            if instance_id[i] not in self.sequence.keys():\n",
    "                self.sequence[instance_id[i]] = []\n",
    "            \n",
    "            self.sequence[instance_id[i]].append(template_id[i])\n",
    "            \n",
    "            self.max_length = max(self.max_length,len(self.sequence[instance_id[i]]))\n",
    "        # add start end\n",
    "        if self.need_start_end:\n",
    "            self.max_length += 2\n",
    "            for key in self.sequence.keys():\n",
    "                self.sequence[key] = [self.start_token] + self.sequence[key] + [self.end_token]               #add start and end\n",
    "\n",
    "        self.update_Dataset()\n",
    "            \n",
    "    def update_Dataset(self,seqs = None ):\n",
    "        # horizon\n",
    "        if self.horizon:\n",
    "            self.max_length = self.horizon * 2 + 1\n",
    "\n",
    "        if seqs == None:\n",
    "            seqs = self.sequence.values()\n",
    "        self.seq_data = []\n",
    "        for seq in seqs:\n",
    "            seq = [int(x) for x in seq]\n",
    "            for i in range(len(seq)):\n",
    "                tmp_seq = seq.copy()\n",
    "                tmp_target = tmp_seq[i]\n",
    "                tmp_seq[i] = self.target_mask\n",
    "                #horzion\n",
    "                if self.horizon:\n",
    "                    tmp_seq = tmp_seq[max(0,i-self.horizon): i+self.horizon]\n",
    "\n",
    "                self.seq_data.append((tmp_seq, tmp_target))\n",
    "            #still a list\n",
    "    \n",
    "    def remove_duplicate(self):\n",
    "        tmp = [json.dumps(x) for x in self.seq_data]\n",
    "        tmp = set(tmp)\n",
    "        self.seq_data = [eval(x) for x in tmp]\n",
    "            \n",
    "    def padding(self,seq):\n",
    "        return seq+[self.padding_number]*(self.max_length-len(seq))\n",
    "    \n",
    "    #Dataset special methods\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.seq_data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        seq = self.seq_data[idx][0]\n",
    "        seq = self.padding(seq)\n",
    "        # save memory\n",
    "        seq = torch.tensor(seq,dtype = torch.long, device=self.device)\n",
    "        target = torch.tensor(self.seq_data[idx][1],dtype = torch.long, device = self.device)\n",
    "        return seq, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hwn_9CsXUuK2"
   },
   "source": [
    "# Define Train Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CWb6XOOU44T"
   },
   "source": [
    "# Define Outlier score calculation function\n",
    "\n",
    "*   input is list of template id; \n",
    "\n",
    "*   max_length not necessarily to be equal with train; \n",
    "*   padding and target but be same to train data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aV-s3Po8h7uz"
   },
   "outputs": [],
   "source": [
    "def outlier_detection_single(seq,model,max_length,padding_number,target_mask,top = 10,inspect = False,max_size = 64,horizon = None):\n",
    "    #prepare data\n",
    "    seq_matrix = []\n",
    "    target = []\n",
    "    seq = [int(x) for x in seq]\n",
    "\n",
    "\n",
    "    for i in range(len(seq)):\n",
    "        tmp_seq = seq.copy()\n",
    "        tmp_target = tmp_seq[i]\n",
    "        tmp_seq[i] = target_mask\n",
    "\n",
    "        if horizon:\n",
    "            tmp_seq = tmp_seq[max(0,i-horizon): i+horizon]\n",
    "            tmp_seq = padding(tmp_seq, horizon*2+1,padding_number)\n",
    "\n",
    "        seq_matrix.append(tmp_seq)\n",
    "        target.append(tmp_target)\n",
    "    \n",
    "    #predict\n",
    "    all_predict = []\n",
    "    device = next(model.parameters()).device\n",
    "    while len(seq_matrix)>0:\n",
    "            X = torch.tensor(seq_matrix[:max_size],device = device)\n",
    "            seq_matrix = seq_matrix[max_size:]\n",
    "            #predict\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                key_padding_mask = (X == padding_number)\n",
    "                output_mask = (X==target_mask)\n",
    "                output = model(X, key_padding_mask = key_padding_mask, result_mask =output_mask )\n",
    "                predict = torch.topk(output,top,dim = 1).indices\n",
    "                all_predict.extend(predict.tolist())\n",
    "    \n",
    "    #outlier score all_predict target\n",
    "    return all_predict, target\n",
    "\n",
    "def padding(seq,max_length,padding_number):\n",
    "    return seq+[padding_number]*(max_length-len(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BbFNJRu_MWtN"
   },
   "outputs": [],
   "source": [
    "def outlier_score_calculation(all_predict, target ,top=1,relative = False, false_position = False):\n",
    "    score = 0\n",
    "    if false_position:\n",
    "        p = []\n",
    "    for i in range(len(target)):\n",
    "        if target[i] not in all_predict[i][:top+1]:\n",
    "            score+=1\n",
    "            if false_position:\n",
    "                p.append(i)\n",
    "    torch.cuda.empty_cache()\n",
    "    if relative:\n",
    "        return score/len(target)\n",
    "    else:\n",
    "        if false_position:\n",
    "            return score,p\n",
    "        else:\n",
    "            return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_k5SYpuG9bce"
   },
   "source": [
    "# load data\n",
    "**hadoop** padding 264 target 0 start 265 end 266 token totally 267"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZVxTR6r9akj"
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "import re\n",
    "import pandas as pd\n",
    "#data\n",
    "hadoop = pd.read_csv('/content/drive/MyDrive/hadoop/hadoop.csv')\n",
    "hadoop['app_id'] = hadoop.Label.str.split('#@#').str[0] \n",
    "### remove master node logs\n",
    "###master_nodes = list(hadoop[hadoop.Content.str.contains('Created MRAppMaster for application')].Label.unique())\n",
    "###hadoop = hadoop[~hadoop.Label.isin(master_nodes)].reset_index(drop = True) \n",
    "\n",
    "# only keep master nodes\n",
    "master_nodes = list(hadoop[hadoop.Content.str.contains('Created MRAppMaster for application')].Label.unique())\n",
    "hadoop = hadoop[hadoop.Label.isin(master_nodes)].reset_index(drop = True)\n",
    "\n",
    "#label\n",
    "label = []\n",
    "with open('/content/drive/MyDrive/hadoop/abnormal_label.txt','r') as data:\n",
    "    for line in data:\n",
    "        if re.search('application_[a-zA-Z0-9_]+',line):\n",
    "            label.append(re.search('application_[a-zA-Z0-9_]+',line).group())\n",
    "        else:\n",
    "            label.append(line)\n",
    "\n",
    "label_normal = label[4:7]+label[38:46]\n",
    "label_normal = [i for i in label_normal if re.search(r'application_[0-9_]*',i)]\n",
    "\n",
    "label_abnormal = [x for x in label if x not in label_normal]\n",
    "label_abnormal = [i for i in label_abnormal if re.search(r'application_[0-9_]*',i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PusqA_ffZNoL",
    "outputId": "3b1e2ded-b04f-4d16-881f-4802e0608a31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hfJP3mtNZPCr",
    "outputId": "8d877200-bdba-4b53-c304-d78ffff3f358"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PTX2utZq_lIY"
   },
   "outputs": [],
   "source": [
    "# train val split\n",
    "train_set = label[4:6] + label[42:46]\n",
    "#train_set =  label[42:44]\n",
    "\n",
    "\n",
    "val_set = [label[6]] + [label[39]]\n",
    "\n",
    "final_test =label_abnormal + [x for x in label_normal if x not in train_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GXjBBHqb_oNf",
    "outputId": "a9cb5456-bc80-4d6e-a867-45bf69eba049"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "train_df = hadoop[hadoop.app_id.isin(train_set)].reset_index(drop = True)\n",
    "val_df = hadoop[hadoop.app_id.isin(val_set)].reset_index(drop = True)\n",
    "test_df = hadoop[hadoop.app_id.isin(final_test)].reset_index(drop = True)\n",
    "print(len(hadoop.Template_id.unique()))\n",
    "print(min(hadoop.Template_id.unique()))\n",
    "#padding 263+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvmpoTuk_rUR"
   },
   "outputs": [],
   "source": [
    "horizon = 20 #30\n",
    "train_sg = sequence_generator(target_mask = 0, padding_number = 264,start_token=265,end_token=266,need_start_end=True,horizon=horizon)\n",
    "val_sg = sequence_generator(target_mask = 0, padding_number = 264,start_token=265,end_token=266,need_start_end=True,horizon=horizon)\n",
    "test_sg = sequence_generator(target_mask = 0, padding_number = 264,start_token=265,end_token=266,need_start_end=True,horizon=horizon)\n",
    "\n",
    "# generate sub sequence dataset\n",
    "train_sg.list_add(train_df['Label'],train_df['Template_id'])\n",
    "val_sg.list_add(val_df['Label'],val_df['Template_id'])\n",
    "test_sg.list_add(test_df['Label'],test_df['Template_id'])\n",
    "\n",
    "train_sg.update_Dataset()\n",
    "val_sg.update_Dataset()\n",
    "test_sg.update_Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "alFexfnU8BNI",
    "outputId": "2094a1ee-4b4e-49d6-e3da-60d1cf5b6118"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 66\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer, seed_everything\n",
    "seed_everything(66, workers=True)\n",
    "model = LogOutlier(ntoken = 267, ninp = 64, nhead = 2, nhid = 64 , nlayers = 4, dropout=0.2, padding_value= 264, target_value= 0)\n",
    "#PATH = '/content/drive/MyDrive/hadoop'+'loss=0.163'+'(ntoken = 267, ninp = 64, nhead = 2, nhid = 64 , nlayers = 4, dropout=0.2, padding_value= 264, target_value= 0)'+'.h5'\n",
    "#model.load_state_dict(torch.load(PATH))\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nwwJmK-9FhL6"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_sg,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392,
     "referenced_widgets": [
      "cfcc3a8df75a488bb51251ae3cd02539",
      "50489f2ba95442fb97ad4b6bc1fa952c",
      "b52130f29baa4d458fc268c9d0bcbf6a",
      "fa190dc401bd4f14909f76509848c9a5",
      "f66879bc7fc342e09b028206e4a6b288",
      "6606b4fb274c46bd8a101e89559c1aab",
      "100f6279af794baabb2b264451fce86f",
      "9ae243a70ce54f84896189eaa1af5a5c",
      "682bb810ee3a4e33808e5b277db9dbc8",
      "2f176c2ec21b4f499e6721cfe92f6e3d",
      "2f74c2728c88499e999317ab3d7fdc9d"
     ]
    },
    "id": "XuwunwPLGiAX",
    "outputId": "b18d9b0a-84ca-4c28-f586-483865e24ab2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using native 16bit precision.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                | Type                        | Params\n",
      "--------------------------------------------------------------------\n",
      "0 | encoder             | Embeddings                  | 17.1 K\n",
      "1 | pos_encoder         | PositionalEncoding          | 0     \n",
      "2 | transformer_encoder | TransformerEncoderAttention | 100 K \n",
      "3 | decoder             | Linear                      | 17.4 K\n",
      "--------------------------------------------------------------------\n",
      "135 K     Trainable params\n",
      "0         Non-trainable params\n",
      "135 K     Total params\n",
      "0.541     Total estimated model params size (MB)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:323: UserWarning: The number of training samples (36) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcc3a8df75a488bb51251ae3cd02539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "trainer = Trainer(precision=16,gpus=1,max_epochs = 60,deterministic=True)\n",
    "\n",
    "trainer.fit(model, train_dataloader)\n",
    "#trainer.fit(model,dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Gd9KfEri8Ym"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "7bbe4df052794f9ea3a1b9a549647bb5",
      "b67c0590f85f4b35b2b8f7eff2e1284d",
      "403b41d5486443d0a4ccf7a9d2796fc0",
      "d419b3f995394a128df507cb37ffe010",
      "6139824704a34d328848197ee2fecdaa",
      "366619d0ae8b46d3bf4d3854a4b761fa",
      "b0169d0ebfce4d9ba2c9d1d578e76432",
      "a085620f6e694cc39f2b116021d9c99b",
      "2a8ef3a177914c2dae701d40bbeea319",
      "a4d5ded3ad0546a9ba199ec51249bd98",
      "e2787628954a4b6dbbaa12079081c357"
     ]
    },
    "id": "UGHm1FqJJIGI",
    "outputId": "fa3e258f-1ffd-4335-a6a2-a5368fbdadf5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbe4df052794f9ea3a1b9a549647bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = []\n",
    "keys = []\n",
    "for i in test_sg.sequence.keys():\n",
    "        keys.append(i)\n",
    "        test.append(test_sg.sequence[i])\n",
    "    #else:\n",
    "        #ground_truth.append(0)\n",
    "#ground_truth = [0]*len(keys)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "model.to(torch.device('cuda'))\n",
    "hdfs_output = []\n",
    "for i in tqdm(test):\n",
    "    hdfs_output.append(outlier_detection_single(i,model,41,264,0,top=10,horizon=horizon)) #2 is best for hdfs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wivejGbfUnj5"
   },
   "outputs": [],
   "source": [
    "def with_different_threshold(hdfs_output,threshold = 1,need_plot = False,false_position = True):    \n",
    "    hdfs_predict = []\n",
    "    position_list = []\n",
    "\n",
    "    ############### prediction with model ####################################\n",
    "    for all_predict, target in tqdm(hdfs_output):\n",
    "        if not false_position:\n",
    "            # don't need to know the position of false prediction in log sentence\n",
    "            hdfs_predict.append(outlier_score_calculation(all_predict, target ,top=threshold,relative=False,false_position=false_position))\n",
    "\n",
    "        else:\n",
    "            # need to know \n",
    "            score,position_ = outlier_score_calculation(all_predict, target ,top=threshold,relative=False,false_position=false_position)\n",
    "            hdfs_predict.append(score)\n",
    "            position_list.append(position_)\n",
    "\n",
    "    ############### evaluation and plot ######################################\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    precision, recall, thresholds = precision_recall_curve(ground_truth, hdfs_predict)\n",
    "    if need_plot:\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        plt.figure(figsize=(10,10))\n",
    "        ax = sns.lineplot(x = recall, y= precision)\n",
    "        ax.set(xlabel='recall', ylabel='precision')\n",
    "        ax.set(ylim=(0,1))\n",
    "        ax.set(xlim=(0,1))\n",
    "        plt.show()\n",
    "\n",
    "    ############### best precision, recall, f1 score #########################\n",
    "    f1 = 0\n",
    "    p = 0\n",
    "    r = 0\n",
    "    for i in range(len(precision)):\n",
    "        f1_ = 2 * precision[i] * recall[i]/(precision[i]+recall[i])\n",
    "        if f1_>f1:\n",
    "            f1 = f1_\n",
    "            p = precision[i]\n",
    "            r = recall[i]\n",
    "    print(p,r,f1)\n",
    "    return (threshold,precision,recall,thresholds,ground_truth,hdfs_predict,position_list), f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "22VwB3P4LtPm"
   },
   "outputs": [],
   "source": [
    "keys = [i.split('#@#')[0] for i in keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kCfrotiPMwL7"
   },
   "outputs": [],
   "source": [
    "ground_truth = []\n",
    "for i in keys:\n",
    "    if i in label_abnormal:\n",
    "        ground_truth.append(1)\n",
    "    else:\n",
    "        ground_truth.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "7c26321eeaec47c384bd4264b36c72d0",
      "a591b038f04a4519acae9b65a1ee5f65",
      "9d0699c4f6e542baba00ae5cb09364ac",
      "7d039dc25e664ec2af165547ba9cfaa1",
      "bfd7c4da86644197b17ff072ede8f412",
      "e18f557c0dc14b4982438ab238afc7a1",
      "034018100ef64c1dacece9fd30453baf",
      "894c758e852f4d489fce4a9269216957",
      "25e50d6f24374a5abef279a38d8f68b1",
      "29c81b4fffb74e3b8b6666e97c727f5f",
      "5f1ee2ab8d6141e2b3bd238a16910d04"
     ]
    },
    "id": "O4b9KpHvz_DS",
    "outputId": "285bc97e-0f2d-437b-de14-b12d0e410ab9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c26321eeaec47c384bd4264b36c72d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95 1.0 0.9743589743589743\n"
     ]
    }
   ],
   "source": [
    "out = with_different_threshold(hdfs_output,3,need_plot= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDxYAvu7WY5m"
   },
   "outputs": [],
   "source": [
    "p = []\n",
    "for i in out[0][-2]:\n",
    "    if i>-1:\n",
    "        p.append(1)\n",
    "    else:\n",
    "        p.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3kjm2JpBWhrE"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zTupAWRFWyVf",
    "outputId": "fc9c116c-11c5-41fa-fa26-e15d7eb970f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.91935484]),\n",
       " array([0., 1.]),\n",
       " array([0.        , 0.95798319]),\n",
       " array([ 5, 57]))"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(ground_truth,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UiAJSsbgUAtf",
    "outputId": "9d0861b3-23bc-460a-de98-e869768139c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 445,\n",
       " 40,\n",
       " 4,\n",
       " 32,\n",
       " 10,\n",
       " 15,\n",
       " 2,\n",
       " 13,\n",
       " 102,\n",
       " 9,\n",
       " 20,\n",
       " 23,\n",
       " 2,\n",
       " 2,\n",
       " 10,\n",
       " 215,\n",
       " 184,\n",
       " 6,\n",
       " 5475,\n",
       " 9,\n",
       " 3332,\n",
       " 12,\n",
       " 29,\n",
       " 4,\n",
       " 1,\n",
       " 58,\n",
       " 78,\n",
       " 666,\n",
       " 10,\n",
       " 10,\n",
       " 14,\n",
       " 8,\n",
       " 7,\n",
       " 60,\n",
       " 43,\n",
       " 46,\n",
       " 2,\n",
       " 10,\n",
       " 1,\n",
       " 22,\n",
       " 48,\n",
       " 8,\n",
       " 14,\n",
       " 2,\n",
       " 16,\n",
       " 30,\n",
       " 3,\n",
       " 0,\n",
       " 133,\n",
       " 74,\n",
       " 2,\n",
       " 4,\n",
       " 26,\n",
       " 28,\n",
       " 15,\n",
       " 10,\n",
       " 3352,\n",
       " 11]"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DcPhQyN8WGAM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TransformerLog_Hadoop.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "034018100ef64c1dacece9fd30453baf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "100f6279af794baabb2b264451fce86f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25e50d6f24374a5abef279a38d8f68b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29c81b4fffb74e3b8b6666e97c727f5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a8ef3a177914c2dae701d40bbeea319": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f176c2ec21b4f499e6721cfe92f6e3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f74c2728c88499e999317ab3d7fdc9d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "366619d0ae8b46d3bf4d3854a4b761fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "403b41d5486443d0a4ccf7a9d2796fc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0169d0ebfce4d9ba2c9d1d578e76432",
      "placeholder": "​",
      "style": "IPY_MODEL_366619d0ae8b46d3bf4d3854a4b761fa",
      "value": "100%"
     }
    },
    "50489f2ba95442fb97ad4b6bc1fa952c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "5f1ee2ab8d6141e2b3bd238a16910d04": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6139824704a34d328848197ee2fecdaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2787628954a4b6dbbaa12079081c357",
      "placeholder": "​",
      "style": "IPY_MODEL_a4d5ded3ad0546a9ba199ec51249bd98",
      "value": " 62/62 [00:10&lt;00:00,  5.99it/s]"
     }
    },
    "6606b4fb274c46bd8a101e89559c1aab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "682bb810ee3a4e33808e5b277db9dbc8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7bbe4df052794f9ea3a1b9a549647bb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_403b41d5486443d0a4ccf7a9d2796fc0",
       "IPY_MODEL_d419b3f995394a128df507cb37ffe010",
       "IPY_MODEL_6139824704a34d328848197ee2fecdaa"
      ],
      "layout": "IPY_MODEL_b67c0590f85f4b35b2b8f7eff2e1284d"
     }
    },
    "7c26321eeaec47c384bd4264b36c72d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9d0699c4f6e542baba00ae5cb09364ac",
       "IPY_MODEL_7d039dc25e664ec2af165547ba9cfaa1",
       "IPY_MODEL_bfd7c4da86644197b17ff072ede8f412"
      ],
      "layout": "IPY_MODEL_a591b038f04a4519acae9b65a1ee5f65"
     }
    },
    "7d039dc25e664ec2af165547ba9cfaa1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25e50d6f24374a5abef279a38d8f68b1",
      "max": 62,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_894c758e852f4d489fce4a9269216957",
      "value": 62
     }
    },
    "894c758e852f4d489fce4a9269216957": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9ae243a70ce54f84896189eaa1af5a5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9d0699c4f6e542baba00ae5cb09364ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_034018100ef64c1dacece9fd30453baf",
      "placeholder": "​",
      "style": "IPY_MODEL_e18f557c0dc14b4982438ab238afc7a1",
      "value": "100%"
     }
    },
    "a085620f6e694cc39f2b116021d9c99b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a4d5ded3ad0546a9ba199ec51249bd98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a591b038f04a4519acae9b65a1ee5f65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0169d0ebfce4d9ba2c9d1d578e76432": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b52130f29baa4d458fc268c9d0bcbf6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_100f6279af794baabb2b264451fce86f",
      "placeholder": "​",
      "style": "IPY_MODEL_6606b4fb274c46bd8a101e89559c1aab",
      "value": "Epoch 59: 100%"
     }
    },
    "b67c0590f85f4b35b2b8f7eff2e1284d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfd7c4da86644197b17ff072ede8f412": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f1ee2ab8d6141e2b3bd238a16910d04",
      "placeholder": "​",
      "style": "IPY_MODEL_29c81b4fffb74e3b8b6666e97c727f5f",
      "value": " 62/62 [00:00&lt;00:00, 733.97it/s]"
     }
    },
    "cfcc3a8df75a488bb51251ae3cd02539": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b52130f29baa4d458fc268c9d0bcbf6a",
       "IPY_MODEL_fa190dc401bd4f14909f76509848c9a5",
       "IPY_MODEL_f66879bc7fc342e09b028206e4a6b288"
      ],
      "layout": "IPY_MODEL_50489f2ba95442fb97ad4b6bc1fa952c"
     }
    },
    "d419b3f995394a128df507cb37ffe010": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a8ef3a177914c2dae701d40bbeea319",
      "max": 62,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a085620f6e694cc39f2b116021d9c99b",
      "value": 62
     }
    },
    "e18f557c0dc14b4982438ab238afc7a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e2787628954a4b6dbbaa12079081c357": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f66879bc7fc342e09b028206e4a6b288": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f74c2728c88499e999317ab3d7fdc9d",
      "placeholder": "​",
      "style": "IPY_MODEL_2f176c2ec21b4f499e6721cfe92f6e3d",
      "value": " 36/36 [00:01&lt;00:00, 27.22it/s, loss=0.303, v_num=5, my_loss_step=0.117, my_loss_epoch=0.298]"
     }
    },
    "fa190dc401bd4f14909f76509848c9a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_682bb810ee3a4e33808e5b277db9dbc8",
      "max": 36,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9ae243a70ce54f84896189eaa1af5a5c",
      "value": 36
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
