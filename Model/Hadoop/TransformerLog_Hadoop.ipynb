{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransformerLog_Hadoop.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cfcc3a8df75a488bb51251ae3cd02539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_50489f2ba95442fb97ad4b6bc1fa952c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b52130f29baa4d458fc268c9d0bcbf6a",
              "IPY_MODEL_fa190dc401bd4f14909f76509848c9a5",
              "IPY_MODEL_f66879bc7fc342e09b028206e4a6b288"
            ]
          }
        },
        "50489f2ba95442fb97ad4b6bc1fa952c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "b52130f29baa4d458fc268c9d0bcbf6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6606b4fb274c46bd8a101e89559c1aab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Epoch 59: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_100f6279af794baabb2b264451fce86f"
          }
        },
        "fa190dc401bd4f14909f76509848c9a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9ae243a70ce54f84896189eaa1af5a5c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 36,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 36,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_682bb810ee3a4e33808e5b277db9dbc8"
          }
        },
        "f66879bc7fc342e09b028206e4a6b288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2f176c2ec21b4f499e6721cfe92f6e3d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 36/36 [00:01&lt;00:00, 27.22it/s, loss=0.303, v_num=5, my_loss_step=0.117, my_loss_epoch=0.298]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f74c2728c88499e999317ab3d7fdc9d"
          }
        },
        "6606b4fb274c46bd8a101e89559c1aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "100f6279af794baabb2b264451fce86f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ae243a70ce54f84896189eaa1af5a5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "682bb810ee3a4e33808e5b277db9dbc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f176c2ec21b4f499e6721cfe92f6e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f74c2728c88499e999317ab3d7fdc9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7bbe4df052794f9ea3a1b9a549647bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b67c0590f85f4b35b2b8f7eff2e1284d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_403b41d5486443d0a4ccf7a9d2796fc0",
              "IPY_MODEL_d419b3f995394a128df507cb37ffe010",
              "IPY_MODEL_6139824704a34d328848197ee2fecdaa"
            ]
          }
        },
        "b67c0590f85f4b35b2b8f7eff2e1284d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "403b41d5486443d0a4ccf7a9d2796fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_366619d0ae8b46d3bf4d3854a4b761fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b0169d0ebfce4d9ba2c9d1d578e76432"
          }
        },
        "d419b3f995394a128df507cb37ffe010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a085620f6e694cc39f2b116021d9c99b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 62,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 62,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a8ef3a177914c2dae701d40bbeea319"
          }
        },
        "6139824704a34d328848197ee2fecdaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a4d5ded3ad0546a9ba199ec51249bd98",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 62/62 [00:10&lt;00:00,  5.99it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e2787628954a4b6dbbaa12079081c357"
          }
        },
        "366619d0ae8b46d3bf4d3854a4b761fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b0169d0ebfce4d9ba2c9d1d578e76432": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a085620f6e694cc39f2b116021d9c99b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a8ef3a177914c2dae701d40bbeea319": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4d5ded3ad0546a9ba199ec51249bd98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e2787628954a4b6dbbaa12079081c357": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c26321eeaec47c384bd4264b36c72d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a591b038f04a4519acae9b65a1ee5f65",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9d0699c4f6e542baba00ae5cb09364ac",
              "IPY_MODEL_7d039dc25e664ec2af165547ba9cfaa1",
              "IPY_MODEL_bfd7c4da86644197b17ff072ede8f412"
            ]
          }
        },
        "a591b038f04a4519acae9b65a1ee5f65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d0699c4f6e542baba00ae5cb09364ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e18f557c0dc14b4982438ab238afc7a1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_034018100ef64c1dacece9fd30453baf"
          }
        },
        "7d039dc25e664ec2af165547ba9cfaa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_894c758e852f4d489fce4a9269216957",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 62,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 62,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25e50d6f24374a5abef279a38d8f68b1"
          }
        },
        "bfd7c4da86644197b17ff072ede8f412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_29c81b4fffb74e3b8b6666e97c727f5f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 62/62 [00:00&lt;00:00, 733.97it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f1ee2ab8d6141e2b3bd238a16910d04"
          }
        },
        "e18f557c0dc14b4982438ab238afc7a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "034018100ef64c1dacece9fd30453baf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "894c758e852f4d489fce4a9269216957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25e50d6f24374a5abef279a38d8f68b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29c81b4fffb74e3b8b6666e97c727f5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f1ee2ab8d6141e2b3bd238a16910d04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkSs-e1STKJo"
      },
      "source": [
        "# Train Test Transformer based log outlier detection framework\n",
        "\n",
        "\n",
        "*   Only suitable for log data that have logical relationship between neighbor logs\n",
        "    - suitable for : HDFS; Hadoop; Openstack\n",
        "    - not suitable for: BGL; Thunderbird (no obvious relationship)  \n",
        "\n",
        "\n",
        "*   Same network architecture, but different embedding size for different log system. Different network objects are separately trained for different log system\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7ZgMtn2Uago"
      },
      "source": [
        "# Preparing\n",
        "\n",
        "\n",
        "*   fix bug of pytorch transformer framework\n",
        "*   Connect to Gdrive\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_DKZlV2GeP7",
        "outputId": "0e81bbd1-6075-4916-e6d5-4150d730b90d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp /content/drive/MyDrive/openstack/functional.py /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\n",
        "#after first copy, restart the notebook\n",
        "\n",
        "\n",
        "try:\n",
        "    from pytorch_lightning.core.lightning import LightningModule\n",
        "except ModuleNotFoundError:\n",
        "    !pip install pytorch-lightning\n",
        "    from pytorch_lightning.core.lightning import LightningModule"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-1.4.2-py3-none-any.whl (916 kB)\n",
            "\u001b[K     |████████████████████████████████| 916 kB 12.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.0)\n",
            "Collecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (3.7.4.3)\n",
            "Collecting torchmetrics>=0.4.0\n",
            "  Downloading torchmetrics-0.5.0-py3-none-any.whl (272 kB)\n",
            "\u001b[K     |████████████████████████████████| 272 kB 67.9 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 61.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.62.0)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 35.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.5.0)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.9.0+cu102)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 65.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 54.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (2.4.7)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.34.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.34.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (57.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.6.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.5.30)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.1)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[K     |████████████████████████████████| 294 kB 69.5 MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.2.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 69.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.5.0)\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=c03c3ec7e46447baea705525aa6953e7db4c4121ff42491f3387a22009e2b362\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built future\n",
            "Installing collected packages: multidict, yarl, async-timeout, fsspec, aiohttp, torchmetrics, PyYAML, pyDeprecate, future, pytorch-lightning\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed PyYAML-5.4.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-2021.7.0 future-0.18.2 multidict-5.1.0 pyDeprecate-0.3.1 pytorch-lightning-1.4.2 torchmetrics-0.5.0 yarl-1.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBVxjbb30IMF"
      },
      "source": [
        "# from torch.nn import Transformer\n",
        "# float 16\n",
        "from pytorch_lightning.core.lightning import LightningModule\n",
        "from pytorch_lightning import LightningDataModule\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from typing import Optional\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import sklearn\n",
        "\n",
        "class LogOutlier(LightningModule):\n",
        "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.2, padding_value = 512, target_value = 0,lr = 1e-3):\n",
        "        super().__init__()\n",
        "        self.lr = lr\n",
        "        self.ninp = ninp\n",
        "        self.padding_value = padding_value\n",
        "        self.target_value = target_value\n",
        "        # token embedding\n",
        "        self.encoder = Embeddings(ninp, ntoken)\n",
        "        # positional encoding\n",
        "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
        "\n",
        "        # transformer encoder\n",
        "        encoder_layers = TransformerEncoderLayerAttention(ninp, nhead, nhid, dropout)  # encoder_layer\n",
        "        self.transformer_encoder = TransformerEncoderAttention(encoder_layers, nlayers)\n",
        "\n",
        "\n",
        "\n",
        "        self.decoder = nn.Linear(ninp, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1  # original 0.1\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, key_padding_mask, att_mask=None, require_attention=False, result_mask=None):\n",
        "        # att_mask : for every sequence in batch is the same\n",
        "        src = src.t()\n",
        "        # pos encoder suppose input begin with sequence length\n",
        "        src = self.encoder(src)\n",
        "\n",
        "        src = self.pos_encoder(src)\n",
        "        # attention! transformer need different input structure, first place is not batch size\n",
        "\n",
        "        output, attention_list = self.transformer_encoder(src, src_key_padding_mask=key_padding_mask, mask=att_mask)\n",
        "\n",
        "        src = None\n",
        "\n",
        "        # change back to normal shape\n",
        "        # att_mask  size(batch_size, sequence length mask)\n",
        "        output = output.permute(1, 0, 2)[result_mask]\n",
        "\n",
        "        output = self.decoder(output)\n",
        "\n",
        "        if require_attention:\n",
        "            return output, attention_list\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        src_key_padding_mask = (x == self.padding_value)\n",
        "        # mask still on same device as x\n",
        "        output_mask = (x == self.target_value)\n",
        "        logits = self(x, key_padding_mask = src_key_padding_mask, result_mask =output_mask )\n",
        "        loss_function = nn.CrossEntropyLoss()\n",
        "        loss = loss_function(logits, y)\n",
        "        self.log('my_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = Adam(self.parameters(), lr=self.lr)\n",
        "        scheduler = StepLR(optimizer, step_size=30, gamma=0.5)\n",
        "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}\n",
        "\n",
        "\n",
        "#######################################################\n",
        "#######################################################\n",
        "\n",
        "class Embeddings(nn.Module):\n",
        "    def __init__(self, d_model, vocab):\n",
        "        # d_model = 0.25*vocab\n",
        "        super(Embeddings, self).__init__()\n",
        "        self.lut = nn.Embedding(vocab, d_model)\n",
        "        self.d_model = d_model\n",
        "        self.lut.weight.data.uniform_(-0.1, 0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lut(x) * math.sqrt(self.d_model)\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    # input must be seq length\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=3000):\n",
        "        # max_len does't affect positional encoding, z.B. for sequence with length 30 ,the positional encoding of 3000 and 30 is exactly same  \n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "\n",
        "class TransformerEncoderLayerAttention(TransformerEncoderLayer):\n",
        "    def forward(self, src: Tensor, src_mask: Optional[Tensor] = None, src_key_padding_mask: Optional[Tensor] = None) :\n",
        "            r\"\"\"Pass the input through the encoder layer.\n",
        "\n",
        "            Args:\n",
        "                src: the sequence to the encoder layer (required).\n",
        "                src_mask: the mask for the src sequence (optional).\n",
        "                src_key_padding_mask: the mask for the src keys per batch (optional).\n",
        "\n",
        "            Shape:\n",
        "                see the docs in Transformer class.\n",
        "            \"\"\"\n",
        "            src2,attention_weight = self.self_attn(src, src, src, attn_mask=src_mask,\n",
        "                                key_padding_mask=src_key_padding_mask)\n",
        "            src = src + self.dropout1(src2)\n",
        "            src = self.norm1(src)\n",
        "            src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
        "            src = src + self.dropout2(src2)\n",
        "            src = self.norm2(src)\n",
        "            return src, attention_weight\n",
        "\n",
        "class TransformerEncoderAttention(TransformerEncoder):\n",
        "    def forward(self, src: Tensor, mask: Optional[Tensor] = None, src_key_padding_mask: Optional[Tensor] = None):\n",
        "            r\"\"\"Pass the input through the encoder layers in turn.\n",
        "\n",
        "            Args:\n",
        "                src: the sequence to the encoder (required).\n",
        "                mask: the mask for the src sequence (optional).\n",
        "                src_key_padding_mask: the mask for the src keys per batch (optional).\n",
        "\n",
        "            Shape:\n",
        "                see the docs in Transformer class.\n",
        "            \"\"\"\n",
        "            output = src\n",
        "            attention_list = []\n",
        "\n",
        "            for mod in self.layers:\n",
        "                output,attention = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask)\n",
        "                attention_list.append(attention.to(torch.device('cpu')))\n",
        "                attention = None\n",
        "            if self.norm is not None:\n",
        "                output = self.norm(output)\n",
        "\n",
        "            return output,attention_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJHLtgQlUllY"
      },
      "source": [
        "# Define Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U56d2CYOUoJ3"
      },
      "source": [
        "# Define Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31zDAQApmWEm"
      },
      "source": [
        "import json\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "class sequence_generator(Dataset):\n",
        "    def __init__(self,target_mask = 0, padding_number = 100, device = torch.device('cpu'), start_token = 62, end_token = 63, need_start_end = False, horizon = False):\n",
        "        if torch.cuda.is_available():\n",
        "            device = torch.device('cuda')\n",
        "        self.tokens = set()\n",
        "        self.sequence = {}\n",
        "        self.max_length = 0# key: instance_id value: template id sequences\n",
        "        self.target_mask = target_mask\n",
        "        self.padding_number = padding_number\n",
        "        \n",
        "        self.seq_data = []\n",
        "        self.device = device\n",
        "\n",
        "        self.start_token = start_token\n",
        "        self.end_token = end_token\n",
        "        self.need_start_end = need_start_end\n",
        "\n",
        "        self.horizon = horizon\n",
        "    \n",
        "    def single_add(self,instance_id,template_id):\n",
        "        self.tokens.update([template_id])\n",
        "        if instance_id not in self.sequence.keys():\n",
        "            self.sequence[instance_id] = []\n",
        "        self.sequence[instance_id].append(template_id)\n",
        "        #update max_length\n",
        "        self.max_length = max(self.max_length,len(self.sequence[instance_id]))\n",
        "    \n",
        "    def list_add(self,instance_id,template_id):\n",
        "        self.tokens.update(template_id)\n",
        "        for i in range(len(instance_id)):\n",
        "            if instance_id[i] not in self.sequence.keys():\n",
        "                self.sequence[instance_id[i]] = []\n",
        "            \n",
        "            self.sequence[instance_id[i]].append(template_id[i])\n",
        "            \n",
        "            self.max_length = max(self.max_length,len(self.sequence[instance_id[i]]))\n",
        "        # add start end\n",
        "        if self.need_start_end:\n",
        "            self.max_length += 2\n",
        "            for key in self.sequence.keys():\n",
        "                self.sequence[key] = [self.start_token] + self.sequence[key] + [self.end_token]               #add start and end\n",
        "\n",
        "        self.update_Dataset()\n",
        "            \n",
        "    def update_Dataset(self,seqs = None ):\n",
        "        # horizon\n",
        "        if self.horizon:\n",
        "            self.max_length = self.horizon * 2 + 1\n",
        "\n",
        "        if seqs == None:\n",
        "            seqs = self.sequence.values()\n",
        "        self.seq_data = []\n",
        "        for seq in seqs:\n",
        "            seq = [int(x) for x in seq]\n",
        "            for i in range(len(seq)):\n",
        "                tmp_seq = seq.copy()\n",
        "                tmp_target = tmp_seq[i]\n",
        "                tmp_seq[i] = self.target_mask\n",
        "                #horzion\n",
        "                if self.horizon:\n",
        "                    tmp_seq = tmp_seq[max(0,i-self.horizon): i+self.horizon]\n",
        "\n",
        "                self.seq_data.append((tmp_seq, tmp_target))\n",
        "            #still a list\n",
        "    \n",
        "    def remove_duplicate(self):\n",
        "        tmp = [json.dumps(x) for x in self.seq_data]\n",
        "        tmp = set(tmp)\n",
        "        self.seq_data = [eval(x) for x in tmp]\n",
        "            \n",
        "    def padding(self,seq):\n",
        "        return seq+[self.padding_number]*(self.max_length-len(seq))\n",
        "    \n",
        "    #Dataset special methods\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.seq_data)\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        seq = self.seq_data[idx][0]\n",
        "        seq = self.padding(seq)\n",
        "        # save memory\n",
        "        seq = torch.tensor(seq,dtype = torch.long, device=self.device)\n",
        "        target = torch.tensor(self.seq_data[idx][1],dtype = torch.long, device = self.device)\n",
        "        return seq, target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hwn_9CsXUuK2"
      },
      "source": [
        "# Define Train Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CWb6XOOU44T"
      },
      "source": [
        "# Define Outlier score calculation function\n",
        "\n",
        "*   input is list of template id; \n",
        "\n",
        "*   max_length not necessarily to be equal with train; \n",
        "*   padding and target but be same to train data\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV-s3Po8h7uz"
      },
      "source": [
        "def outlier_detection_single(seq,model,max_length,padding_number,target_mask,top = 10,inspect = False,max_size = 64,horizon = None):\n",
        "    #prepare data\n",
        "    seq_matrix = []\n",
        "    target = []\n",
        "    seq = [int(x) for x in seq]\n",
        "\n",
        "\n",
        "    for i in range(len(seq)):\n",
        "        tmp_seq = seq.copy()\n",
        "        tmp_target = tmp_seq[i]\n",
        "        tmp_seq[i] = target_mask\n",
        "\n",
        "        if horizon:\n",
        "            tmp_seq = tmp_seq[max(0,i-horizon): i+horizon]\n",
        "            tmp_seq = padding(tmp_seq, horizon*2+1,padding_number)\n",
        "\n",
        "        seq_matrix.append(tmp_seq)\n",
        "        target.append(tmp_target)\n",
        "    \n",
        "    #predict\n",
        "    all_predict = []\n",
        "    device = next(model.parameters()).device\n",
        "    while len(seq_matrix)>0:\n",
        "            X = torch.tensor(seq_matrix[:max_size],device = device)\n",
        "            seq_matrix = seq_matrix[max_size:]\n",
        "            #predict\n",
        "            with torch.no_grad():\n",
        "                model.eval()\n",
        "                key_padding_mask = (X == padding_number)\n",
        "                output_mask = (X==target_mask)\n",
        "                output = model(X, key_padding_mask = key_padding_mask, result_mask =output_mask )\n",
        "                predict = torch.topk(output,top,dim = 1).indices\n",
        "                all_predict.extend(predict.tolist())\n",
        "    \n",
        "    #outlier score all_predict target\n",
        "    return all_predict, target\n",
        "\n",
        "def padding(seq,max_length,padding_number):\n",
        "    return seq+[padding_number]*(max_length-len(seq))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbFNJRu_MWtN"
      },
      "source": [
        "def outlier_score_calculation(all_predict, target ,top=1,relative = False, false_position = False):\n",
        "    score = 0\n",
        "    if false_position:\n",
        "        p = []\n",
        "    for i in range(len(target)):\n",
        "        if target[i] not in all_predict[i][:top+1]:\n",
        "            score+=1\n",
        "            if false_position:\n",
        "                p.append(i)\n",
        "    torch.cuda.empty_cache()\n",
        "    if relative:\n",
        "        return score/len(target)\n",
        "    else:\n",
        "        if false_position:\n",
        "            return score,p\n",
        "        else:\n",
        "            return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_k5SYpuG9bce"
      },
      "source": [
        "# load data\n",
        "**hadoop** padding 264 target 0 start 265 end 266 token totally 267"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZVxTR6r9akj"
      },
      "source": [
        "# load data\n",
        "import re\n",
        "import pandas as pd\n",
        "#data\n",
        "hadoop = pd.read_csv('/content/drive/MyDrive/hadoop/hadoop.csv')\n",
        "hadoop['app_id'] = hadoop.Label.str.split('#@#').str[0] \n",
        "### remove master node logs\n",
        "###master_nodes = list(hadoop[hadoop.Content.str.contains('Created MRAppMaster for application')].Label.unique())\n",
        "###hadoop = hadoop[~hadoop.Label.isin(master_nodes)].reset_index(drop = True) \n",
        "\n",
        "# only keep master nodes\n",
        "master_nodes = list(hadoop[hadoop.Content.str.contains('Created MRAppMaster for application')].Label.unique())\n",
        "hadoop = hadoop[hadoop.Label.isin(master_nodes)].reset_index(drop = True)\n",
        "\n",
        "#label\n",
        "label = []\n",
        "with open('/content/drive/MyDrive/hadoop/abnormal_label.txt','r') as data:\n",
        "    for line in data:\n",
        "        if re.search('application_[a-zA-Z0-9_]+',line):\n",
        "            label.append(re.search('application_[a-zA-Z0-9_]+',line).group())\n",
        "        else:\n",
        "            label.append(line)\n",
        "\n",
        "label_normal = label[4:7]+label[38:46]\n",
        "label_normal = [i for i in label_normal if re.search(r'application_[0-9_]*',i)]\n",
        "\n",
        "label_abnormal = [x for x in label if x not in label_normal]\n",
        "label_abnormal = [i for i in label_abnormal if re.search(r'application_[0-9_]*',i)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PusqA_ffZNoL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b1e2ded-b04f-4d16-881f-4802e0608a31"
      },
      "source": [
        "len(label_abnormal)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfJP3mtNZPCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d877200-bdba-4b53-c304-d78ffff3f358"
      },
      "source": [
        "len(final_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTX2utZq_lIY"
      },
      "source": [
        "# train val split\n",
        "train_set = label[4:6] + label[42:46]\n",
        "#train_set =  label[42:44]\n",
        "\n",
        "\n",
        "val_set = [label[6]] + [label[39]]\n",
        "\n",
        "final_test =label_abnormal + [x for x in label_normal if x not in train_set]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXjBBHqb_oNf",
        "outputId": "a9cb5456-bc80-4d6e-a867-45bf69eba049"
      },
      "source": [
        "train_df = hadoop[hadoop.app_id.isin(train_set)].reset_index(drop = True)\n",
        "val_df = hadoop[hadoop.app_id.isin(val_set)].reset_index(drop = True)\n",
        "test_df = hadoop[hadoop.app_id.isin(final_test)].reset_index(drop = True)\n",
        "print(len(hadoop.Template_id.unique()))\n",
        "print(min(hadoop.Template_id.unique()))\n",
        "#padding 263+1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "191\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvmpoTuk_rUR"
      },
      "source": [
        "horizon = 20 #30\n",
        "train_sg = sequence_generator(target_mask = 0, padding_number = 264,start_token=265,end_token=266,need_start_end=True,horizon=horizon)\n",
        "val_sg = sequence_generator(target_mask = 0, padding_number = 264,start_token=265,end_token=266,need_start_end=True,horizon=horizon)\n",
        "test_sg = sequence_generator(target_mask = 0, padding_number = 264,start_token=265,end_token=266,need_start_end=True,horizon=horizon)\n",
        "\n",
        "# generate sub sequence dataset\n",
        "train_sg.list_add(train_df['Label'],train_df['Template_id'])\n",
        "val_sg.list_add(val_df['Label'],val_df['Template_id'])\n",
        "test_sg.list_add(test_df['Label'],test_df['Template_id'])\n",
        "\n",
        "train_sg.update_Dataset()\n",
        "val_sg.update_Dataset()\n",
        "test_sg.update_Dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alFexfnU8BNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2094a1ee-4b4e-49d6-e3da-60d1cf5b6118"
      },
      "source": [
        "from pytorch_lightning import Trainer, seed_everything\n",
        "seed_everything(66, workers=True)\n",
        "model = LogOutlier(ntoken = 267, ninp = 64, nhead = 2, nhid = 64 , nlayers = 4, dropout=0.2, padding_value= 264, target_value= 0)\n",
        "#PATH = '/content/drive/MyDrive/hadoop'+'loss=0.163'+'(ntoken = 267, ninp = 64, nhead = 2, nhid = 64 , nlayers = 4, dropout=0.2, padding_value= 264, target_value= 0)'+'.h5'\n",
        "#model.load_state_dict(torch.load(PATH))\n",
        "#model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 66\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwwJmK-9FhL6"
      },
      "source": [
        "train_dataloader = DataLoader(train_sg,256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392,
          "referenced_widgets": [
            "cfcc3a8df75a488bb51251ae3cd02539",
            "50489f2ba95442fb97ad4b6bc1fa952c",
            "b52130f29baa4d458fc268c9d0bcbf6a",
            "fa190dc401bd4f14909f76509848c9a5",
            "f66879bc7fc342e09b028206e4a6b288",
            "6606b4fb274c46bd8a101e89559c1aab",
            "100f6279af794baabb2b264451fce86f",
            "9ae243a70ce54f84896189eaa1af5a5c",
            "682bb810ee3a4e33808e5b277db9dbc8",
            "2f176c2ec21b4f499e6721cfe92f6e3d",
            "2f74c2728c88499e999317ab3d7fdc9d"
          ]
        },
        "id": "XuwunwPLGiAX",
        "outputId": "b18d9b0a-84ca-4c28-f586-483865e24ab2"
      },
      "source": [
        "from pytorch_lightning import Trainer\n",
        "trainer = Trainer(precision=16,gpus=1,max_epochs = 60,deterministic=True)\n",
        "\n",
        "trainer.fit(model, train_dataloader)\n",
        "#trainer.fit(model,dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using native 16bit precision.\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name                | Type                        | Params\n",
            "--------------------------------------------------------------------\n",
            "0 | encoder             | Embeddings                  | 17.1 K\n",
            "1 | pos_encoder         | PositionalEncoding          | 0     \n",
            "2 | transformer_encoder | TransformerEncoderAttention | 100 K \n",
            "3 | decoder             | Linear                      | 17.4 K\n",
            "--------------------------------------------------------------------\n",
            "135 K     Trainable params\n",
            "0         Non-trainable params\n",
            "135 K     Total params\n",
            "0.541     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:323: UserWarning: The number of training samples (36) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfcc3a8df75a488bb51251ae3cd02539",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Training: -1it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Gd9KfEri8Ym"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "7bbe4df052794f9ea3a1b9a549647bb5",
            "b67c0590f85f4b35b2b8f7eff2e1284d",
            "403b41d5486443d0a4ccf7a9d2796fc0",
            "d419b3f995394a128df507cb37ffe010",
            "6139824704a34d328848197ee2fecdaa",
            "366619d0ae8b46d3bf4d3854a4b761fa",
            "b0169d0ebfce4d9ba2c9d1d578e76432",
            "a085620f6e694cc39f2b116021d9c99b",
            "2a8ef3a177914c2dae701d40bbeea319",
            "a4d5ded3ad0546a9ba199ec51249bd98",
            "e2787628954a4b6dbbaa12079081c357"
          ]
        },
        "id": "UGHm1FqJJIGI",
        "outputId": "fa3e258f-1ffd-4335-a6a2-a5368fbdadf5"
      },
      "source": [
        "test = []\n",
        "keys = []\n",
        "for i in test_sg.sequence.keys():\n",
        "        keys.append(i)\n",
        "        test.append(test_sg.sequence[i])\n",
        "    #else:\n",
        "        #ground_truth.append(0)\n",
        "#ground_truth = [0]*len(keys)\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "model.to(torch.device('cuda'))\n",
        "hdfs_output = []\n",
        "for i in tqdm(test):\n",
        "    hdfs_output.append(outlier_detection_single(i,model,41,264,0,top=10,horizon=horizon)) #2 is best for hdfs\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7bbe4df052794f9ea3a1b9a549647bb5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/62 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wivejGbfUnj5"
      },
      "source": [
        "def with_different_threshold(hdfs_output,threshold = 1,need_plot = False,false_position = True):    \n",
        "    hdfs_predict = []\n",
        "    position_list = []\n",
        "\n",
        "    ############### prediction with model ####################################\n",
        "    for all_predict, target in tqdm(hdfs_output):\n",
        "        if not false_position:\n",
        "            # don't need to know the position of false prediction in log sentence\n",
        "            hdfs_predict.append(outlier_score_calculation(all_predict, target ,top=threshold,relative=False,false_position=false_position))\n",
        "\n",
        "        else:\n",
        "            # need to know \n",
        "            score,position_ = outlier_score_calculation(all_predict, target ,top=threshold,relative=False,false_position=false_position)\n",
        "            hdfs_predict.append(score)\n",
        "            position_list.append(position_)\n",
        "\n",
        "    ############### evaluation and plot ######################################\n",
        "    from sklearn.metrics import precision_recall_curve\n",
        "    precision, recall, thresholds = precision_recall_curve(ground_truth, hdfs_predict)\n",
        "    if need_plot:\n",
        "        import matplotlib.pyplot as plt\n",
        "        import seaborn as sns\n",
        "        plt.figure(figsize=(10,10))\n",
        "        ax = sns.lineplot(x = recall, y= precision)\n",
        "        ax.set(xlabel='recall', ylabel='precision')\n",
        "        ax.set(ylim=(0,1))\n",
        "        ax.set(xlim=(0,1))\n",
        "        plt.show()\n",
        "\n",
        "    ############### best precision, recall, f1 score #########################\n",
        "    f1 = 0\n",
        "    p = 0\n",
        "    r = 0\n",
        "    for i in range(len(precision)):\n",
        "        f1_ = 2 * precision[i] * recall[i]/(precision[i]+recall[i])\n",
        "        if f1_>f1:\n",
        "            f1 = f1_\n",
        "            p = precision[i]\n",
        "            r = recall[i]\n",
        "    print(p,r,f1)\n",
        "    return (threshold,precision,recall,thresholds,ground_truth,hdfs_predict,position_list), f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22VwB3P4LtPm"
      },
      "source": [
        "keys = [i.split('#@#')[0] for i in keys]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCfrotiPMwL7"
      },
      "source": [
        "ground_truth = []\n",
        "for i in keys:\n",
        "    if i in label_abnormal:\n",
        "        ground_truth.append(1)\n",
        "    else:\n",
        "        ground_truth.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4b9KpHvz_DS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "7c26321eeaec47c384bd4264b36c72d0",
            "a591b038f04a4519acae9b65a1ee5f65",
            "9d0699c4f6e542baba00ae5cb09364ac",
            "7d039dc25e664ec2af165547ba9cfaa1",
            "bfd7c4da86644197b17ff072ede8f412",
            "e18f557c0dc14b4982438ab238afc7a1",
            "034018100ef64c1dacece9fd30453baf",
            "894c758e852f4d489fce4a9269216957",
            "25e50d6f24374a5abef279a38d8f68b1",
            "29c81b4fffb74e3b8b6666e97c727f5f",
            "5f1ee2ab8d6141e2b3bd238a16910d04"
          ]
        },
        "outputId": "285bc97e-0f2d-437b-de14-b12d0e410ab9"
      },
      "source": [
        "out = with_different_threshold(hdfs_output,3,need_plot= False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c26321eeaec47c384bd4264b36c72d0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/62 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.95 1.0 0.9743589743589743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDxYAvu7WY5m"
      },
      "source": [
        "p = []\n",
        "for i in out[0][-2]:\n",
        "    if i>-1:\n",
        "        p.append(1)\n",
        "    else:\n",
        "        p.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kjm2JpBWhrE"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTupAWRFWyVf",
        "outputId": "fc9c116c-11c5-41fa-fa26-e15d7eb970f4"
      },
      "source": [
        "precision_recall_fscore_support(ground_truth,p)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.        , 0.91935484]),\n",
              " array([0., 1.]),\n",
              " array([0.        , 0.95798319]),\n",
              " array([ 5, 57]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiAJSsbgUAtf",
        "outputId": "9d0861b3-23bc-460a-de98-e869768139c8"
      },
      "source": [
        "out[0][-2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[32,\n",
              " 1,\n",
              " 3,\n",
              " 0,\n",
              " 445,\n",
              " 40,\n",
              " 4,\n",
              " 32,\n",
              " 10,\n",
              " 15,\n",
              " 2,\n",
              " 13,\n",
              " 102,\n",
              " 9,\n",
              " 20,\n",
              " 23,\n",
              " 2,\n",
              " 2,\n",
              " 10,\n",
              " 215,\n",
              " 184,\n",
              " 6,\n",
              " 5475,\n",
              " 9,\n",
              " 3332,\n",
              " 12,\n",
              " 29,\n",
              " 4,\n",
              " 1,\n",
              " 58,\n",
              " 78,\n",
              " 666,\n",
              " 10,\n",
              " 10,\n",
              " 14,\n",
              " 8,\n",
              " 7,\n",
              " 60,\n",
              " 43,\n",
              " 46,\n",
              " 2,\n",
              " 10,\n",
              " 1,\n",
              " 22,\n",
              " 48,\n",
              " 8,\n",
              " 14,\n",
              " 2,\n",
              " 16,\n",
              " 30,\n",
              " 3,\n",
              " 0,\n",
              " 133,\n",
              " 74,\n",
              " 2,\n",
              " 4,\n",
              " 26,\n",
              " 28,\n",
              " 15,\n",
              " 10,\n",
              " 3352,\n",
              " 11]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcPhQyN8WGAM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}